{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo_BUq2oYAzB"
      },
      "source": [
        "# !pip install -U git+https://github.com/albu/albumentations --no-cache-dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd58OqEUJEb5"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import transforms\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import glob2\n",
        "import numpy as np\n",
        "import albumentations as A \n",
        "import copy\n",
        "from albumentations.pytorch import ToTensor\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import subprocess"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npXqteGc0Ueq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb69a594-81c9-4230-872c-5b169c0421d1"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# ! tar -xf /content/drive/MyDrive/Colab\\ Notebooks/Unet/CelebAMask-HQ-mask-anno.tar \n",
        "# ! tar -xf /content/drive/MyDrive/Colab\\ Notebooks/Unet/CelebA-HQ-img.tar"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjqgX3mjZEnc"
      },
      "source": [
        "## HyperParameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_o4fOvwZ6qQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GawyfqVHZEY0"
      },
      "source": [
        "train_test_split = 0.9\n",
        "lr =  0.01\n",
        "batch_size = 16\n",
        "epochs = 20\n",
        "images_path = '/content/CelebA-HQ-img/'\n",
        "anno_path = '/content/CelebAMask-HQ-mask-anno/'\n",
        "device = 'cuda'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69o4aDKE6UtB"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOpnQDDU2Xoa"
      },
      "source": [
        "# Data Clearning \n",
        "def delete_imgs_for_no_anno(images_path,anno_path):\n",
        "  image_list =  glob2.glob(images_path+\"/*jpg\")\n",
        "  for i,image in enumerate(image_list):\n",
        "    # image_name = str(i) +\".jpg\"\n",
        "    # image = images_path + \"/\" + image_name\n",
        "    # print(image)\n",
        "    # print(i)\n",
        "    id =  int(image.split(\"/\")[-1].split(\".\")[0])\n",
        "\n",
        "    l_eye_name = ''.join([str(id).rjust(5, '0'), '_', 'l_eye', '.png'])\n",
        "    r_eye_name = ''.join([str(id).rjust(5, '0'), '_', 'r_eye', '.png'])\n",
        "    u_lip_name = ''.join([str(id).rjust(5, '0'), '_', 'u_lip', '.png'])\n",
        "    l_lip_name = ''.join([str(id).rjust(5, '0'), '_', 'l_lip', '.png'])   \n",
        "\n",
        "    anno_sub_folder = int( id / 2000)\n",
        "\n",
        "    l_eye_path = anno_path +  \"/\" + str(anno_sub_folder) + \"/\" + l_eye_name\n",
        "    r_eye_path = anno_path + \"/\"  + str(anno_sub_folder) + \"/\" + r_eye_name\n",
        "    u_lip_path = anno_path + \"/\"  + str(anno_sub_folder) + \"/\" + u_lip_name\n",
        "    l_lip_path = anno_path + \"/\"  + str(anno_sub_folder) + \"/\" + l_lip_name \n",
        "\n",
        "    if not (os.path.isfile(l_eye_path) and os.path.isfile(r_eye_path) and os.path.isfile(u_lip_path) and os.path.isfile(l_lip_path) ):\n",
        "      print(\"deleting file\",image)\n",
        "      cmd = 'rm -rf ' + image\n",
        "      # try:\n",
        "      #   os.remove(image)\n",
        "      # except:\n",
        "      #   a=1\n",
        "      subprocess.run( cmd ,shell=True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hheZZWdT8JwN"
      },
      "source": [
        "# delete_imgs_for_no_anno(images_path,anno_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GctB6Yz8JFyl"
      },
      "source": [
        "## Dataset / DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BrqT8wGJE-7"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class mask_dataset(Dataset):\n",
        "  def __init__(self, images_path, anno_path, transform, data_type, train_test_split, image_list):\n",
        "    self.images_path = images_path\n",
        "    self.anno_path = anno_path\n",
        "    self.transform = transform\n",
        "    self.imagelist = image_list\n",
        "    self.data_type = data_type\n",
        "    self.train_test_split = train_test_split\n",
        "\n",
        "  def combine_mask_images(self, img1_path, img2_path):\n",
        "    img1_mask = cv2.imread(img1_path ,cv2.IMREAD_GRAYSCALE)\n",
        "    img2_mask = cv2.imread(img2_path ,cv2.IMREAD_GRAYSCALE)\n",
        "    mask = img2_mask > 0.5\n",
        "    comb_mask = img1_mask.copy()\n",
        "    comb_mask[mask] = img2_mask[mask]\n",
        "    return comb_mask\n",
        "\n",
        "\n",
        "  def __getitem__(self,id):\n",
        "    idx = int(self.imagelist[id].split(\"/\")[-1].split(\".\")[0])\n",
        "\n",
        "    if (self.data_type == 'test'):\n",
        "      id = id + int( train_test_split * len(self.imagelist) )\n",
        "      idx = int(self.imagelist[id].split(\"/\")[-1].split(\".\")[0])\n",
        "\n",
        "    image_name = str(idx) +\".jpg\"\n",
        "    l_eye_name = ''.join([str(idx).rjust(5, '0'), '_', 'l_eye', '.png'])\n",
        "    r_eye_name = ''.join([str(idx).rjust(5, '0'), '_', 'r_eye', '.png'])\n",
        "    u_lip_name = ''.join([str(idx).rjust(5, '0'), '_', 'u_lip', '.png'])\n",
        "    l_lip_name = ''.join([str(idx).rjust(5, '0'), '_', 'l_lip', '.png'])\n",
        "\n",
        "    anno_sub_folder = int( idx / 2000)\n",
        "\n",
        "    image_path = self.images_path + \"/\" + image_name\n",
        "    # print(\"image_path\",image_path)\n",
        "    l_eye_path = self.anno_path +  \"/\" + str(anno_sub_folder) + \"/\" + l_eye_name\n",
        "    r_eye_path = self.anno_path + \"/\"  + str(anno_sub_folder) + \"/\" + r_eye_name\n",
        "    u_lip_path = self.anno_path + \"/\"  + str(anno_sub_folder) + \"/\" + u_lip_name\n",
        "    l_lip_path = self.anno_path + \"/\"  + str(anno_sub_folder) + \"/\" + l_lip_name\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (512, 512), interpolation = cv2.INTER_NEAREST)\n",
        "\n",
        "    # l_eye_mask = cv2.imread(l_eye_path,cv2.IMREAD_GRAYSCALE)\n",
        "    # r_eye_mask = cv2.imread(r_eye_path,cv2.IMREAD_GRAYSCALE)\n",
        "    # u_lip_mask = cv2.imread(u_lip_path,cv2.IMREAD_GRAYSCALE)\n",
        "    # l_lip_mask = cv2.imread(l_lip_path,cv2.IMREAD_GRAYSCALE)\n",
        "    # masks = [l_eye_mask,r_eye_mask,u_lip_mask,l_lip_mask]\n",
        "\n",
        "    # print(\"image_path:\",image_path)\n",
        "    # print(\"l_eye_path:\",l_eye_path)\n",
        "    eye_mask = self.combine_mask_images(l_eye_path,r_eye_path)\n",
        "    lip_mask = self.combine_mask_images(u_lip_path,l_lip_path)\n",
        "    masks = [eye_mask,lip_mask]\n",
        "\n",
        "    transformed = self.transform(image=image, masks=masks) # one face, several  masks\n",
        "    transformed_image = transformed['image']\n",
        "    transformed_masks = transformed['masks']\n",
        "    transformed_masks = torch.stack([ torch.from_numpy(transformed_masks[0]), torch.from_numpy(transformed_masks[1]) ]) # (2,512,512)\n",
        "    # transformed_masks = torch.stack([ torch.from_numpy(transformed_masks[0]), torch.from_numpy(transformed_masks[1]),\n",
        "    #                                  torch.from_numpy(transformed_masks[2]), torch.from_numpy(transformed_masks[3])]) # (4,512,512)\n",
        "    transformed_masks = transformed_masks / 255.0\n",
        "    return transformed_image,transformed_masks\n",
        "\n",
        "  def __len__(self):\n",
        "    total_image = len(self.imagelist)\n",
        "    if (self.data_type == 'train'):\n",
        "      num_dataset = int(self.train_test_split * total_image) \n",
        "    else:\n",
        "      num_dataset = int ((1.0-self.train_test_split)*total_image)\n",
        "    return num_dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jtl7TNWeJCKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca0eb65-11d1-4b56-f92e-b791a2fa5e13"
      },
      "source": [
        "train_transform = A.Compose(\n",
        "    [\n",
        "        # A.Resize(256, 256),\n",
        "        A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=15, p=0.2),\n",
        "        # A.HorizontalFlip(p=0.5),\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.2),\n",
        "        ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(512, 512),\n",
        "        ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/albumentations/pytorch/transforms.py:58: FutureWarning: ToTensor is deprecated and will be replaced by ToTensorV2 in albumentations 0.7.0\n",
            "  \"ToTensor is deprecated and will be replaced by ToTensorV2 in albumentations 0.7.0\", FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DZvNQfPokmt"
      },
      "source": [
        "# image_list = glob2.glob(images_path+\"/*jpg\")\n",
        "\n",
        "# import pickle\n",
        "\n",
        "# output = open('image_list.pkl', 'wb')\n",
        "# pickle.dump(image_list, output)\n",
        "# output.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bGQBOS2YZvB"
      },
      "source": [
        "import pickle\n",
        "file = open('image_list.pkl', 'rb')\n",
        "image_list = pickle.load(file)\n",
        "file.close()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuJ5ore5ZSBe"
      },
      "source": [
        "train_dataset = mask_dataset(images_path, anno_path, train_transform,'train', train_test_split, image_list)\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = mask_dataset(images_path, anno_path, val_transform,'test', train_test_split, image_list)\n",
        "val_dataloader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_rcav9caY8-"
      },
      "source": [
        "def visualize_augmentations(dataset, idx=0, samples=5):\n",
        "    dataset = copy.deepcopy(dataset)\n",
        "    figure, ax = plt.subplots(nrows=samples, ncols=3, figsize=(18, 84))\n",
        "    for i in range(samples):\n",
        "        tensor_image, tensor_masks = dataset[idx+i]\n",
        "        ax[i, 0].imshow(tensor_image.permute(1, 2, 0)) # (3,512,512) --> (512,512,3)\n",
        "        ax[i, 2].imshow(tensor_masks[0].squeeze(), interpolation=\"nearest\")  # (1,512,512) to (512,512)\n",
        "        ax[i, 1].imshow(tensor_masks[1].squeeze(), interpolation=\"nearest\") \n",
        "        # ax[i, 3].imshow(tensor_masks[2].squeeze(), interpolation=\"nearest\")  # (1,512,512) to (512,512)\n",
        "        # ax[i, 4].imshow(tensor_masks[3].squeeze(), interpolation=\"nearest\") \n",
        "        ax[i, 0].set_title(\"Augmented image\")\n",
        "        ax[i, 2].set_title(\"Augmented eye\")\n",
        "        ax[i, 1].set_title(\"Augmented lips\")\n",
        "        # ax[i, 3].set_title(\"Augmented upper lips\")\n",
        "        # ax[i, 4].set_title(\"Augmented lower lips\")\n",
        "        ax[i, 0].set_axis_off()\n",
        "        ax[i, 1].set_axis_off()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiLviFj1an10"
      },
      "source": [
        "# visualize_augmentations(train_dataset,idx=0,samples=20)\n",
        "# Refer README.md for visualize_augmentations output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8POZgzMJCkf"
      },
      "source": [
        "## UNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHZQGiZwHGyC"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "# class OutConv(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(OutConv, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "#         self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.conv2(self.conv1(x))\n",
        "\n",
        "class light_capicity_Conv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(light_capicity_Conv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te0Vlq_6-IC3"
      },
      "source": [
        "class high_capicity_conv(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels):\n",
        "    super(high_capicity_conv, self).__init__()\n",
        "    self.capicity_conv = nn.Sequential(\n",
        "            DoubleConv(in_channels, in_channels),\n",
        "            DoubleConv(in_channels, in_channels),\n",
        "            DoubleConv(in_channels, in_channels)\n",
        "        )\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.capicity_conv(x)\n",
        "    x = self.conv(x)\n",
        "    return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAvbbcREFdv8"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 16)\n",
        "        self.down1 = Down(16, 32)\n",
        "        self.down2 = Down(32, 64)\n",
        "        self.down3 = Down(64, 128)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(128, 256 // factor)\n",
        "        self.up1 = Up(256, 128 // factor, bilinear)\n",
        "        self.up2 = Up(128, 64 // factor, bilinear)\n",
        "        self.up3 = Up(64, 32 // factor, bilinear)\n",
        "        self.up4 = Up(32, 16, bilinear)\n",
        "        # self.outc = OutConv(16, n_classes)\n",
        "        self.eyes = high_capicity_conv(16,1)\n",
        "        self.lips = high_capicity_conv(16,1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        eyes = self.eyes(x)\n",
        "        lips = self.lips(x)\n",
        "        return eyes,lips\n",
        "        # logits = self.outc(x)\n",
        "        # return logits"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOwxA77xHTKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad54066c-37b1-4141-c9a7-d6283ddc28ef"
      },
      "source": [
        "unet = UNet(n_channels=3, n_classes=2)\n",
        "unet.to(device)\n",
        "\n",
        "from torchsummary import summary\n",
        "summary(unet, (3, 512, 512))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 512, 512]             448\n",
            "       BatchNorm2d-2         [-1, 16, 512, 512]              32\n",
            "              ReLU-3         [-1, 16, 512, 512]               0\n",
            "            Conv2d-4         [-1, 16, 512, 512]           2,320\n",
            "       BatchNorm2d-5         [-1, 16, 512, 512]              32\n",
            "              ReLU-6         [-1, 16, 512, 512]               0\n",
            "        DoubleConv-7         [-1, 16, 512, 512]               0\n",
            "         MaxPool2d-8         [-1, 16, 256, 256]               0\n",
            "            Conv2d-9         [-1, 32, 256, 256]           4,640\n",
            "      BatchNorm2d-10         [-1, 32, 256, 256]              64\n",
            "             ReLU-11         [-1, 32, 256, 256]               0\n",
            "           Conv2d-12         [-1, 32, 256, 256]           9,248\n",
            "      BatchNorm2d-13         [-1, 32, 256, 256]              64\n",
            "             ReLU-14         [-1, 32, 256, 256]               0\n",
            "       DoubleConv-15         [-1, 32, 256, 256]               0\n",
            "             Down-16         [-1, 32, 256, 256]               0\n",
            "        MaxPool2d-17         [-1, 32, 128, 128]               0\n",
            "           Conv2d-18         [-1, 64, 128, 128]          18,496\n",
            "      BatchNorm2d-19         [-1, 64, 128, 128]             128\n",
            "             ReLU-20         [-1, 64, 128, 128]               0\n",
            "           Conv2d-21         [-1, 64, 128, 128]          36,928\n",
            "      BatchNorm2d-22         [-1, 64, 128, 128]             128\n",
            "             ReLU-23         [-1, 64, 128, 128]               0\n",
            "       DoubleConv-24         [-1, 64, 128, 128]               0\n",
            "             Down-25         [-1, 64, 128, 128]               0\n",
            "        MaxPool2d-26           [-1, 64, 64, 64]               0\n",
            "           Conv2d-27          [-1, 128, 64, 64]          73,856\n",
            "      BatchNorm2d-28          [-1, 128, 64, 64]             256\n",
            "             ReLU-29          [-1, 128, 64, 64]               0\n",
            "           Conv2d-30          [-1, 128, 64, 64]         147,584\n",
            "      BatchNorm2d-31          [-1, 128, 64, 64]             256\n",
            "             ReLU-32          [-1, 128, 64, 64]               0\n",
            "       DoubleConv-33          [-1, 128, 64, 64]               0\n",
            "             Down-34          [-1, 128, 64, 64]               0\n",
            "        MaxPool2d-35          [-1, 128, 32, 32]               0\n",
            "           Conv2d-36          [-1, 128, 32, 32]         147,584\n",
            "      BatchNorm2d-37          [-1, 128, 32, 32]             256\n",
            "             ReLU-38          [-1, 128, 32, 32]               0\n",
            "           Conv2d-39          [-1, 128, 32, 32]         147,584\n",
            "      BatchNorm2d-40          [-1, 128, 32, 32]             256\n",
            "             ReLU-41          [-1, 128, 32, 32]               0\n",
            "       DoubleConv-42          [-1, 128, 32, 32]               0\n",
            "             Down-43          [-1, 128, 32, 32]               0\n",
            "         Upsample-44          [-1, 128, 64, 64]               0\n",
            "           Conv2d-45          [-1, 128, 64, 64]         295,040\n",
            "      BatchNorm2d-46          [-1, 128, 64, 64]             256\n",
            "             ReLU-47          [-1, 128, 64, 64]               0\n",
            "           Conv2d-48           [-1, 64, 64, 64]          73,792\n",
            "      BatchNorm2d-49           [-1, 64, 64, 64]             128\n",
            "             ReLU-50           [-1, 64, 64, 64]               0\n",
            "       DoubleConv-51           [-1, 64, 64, 64]               0\n",
            "               Up-52           [-1, 64, 64, 64]               0\n",
            "         Upsample-53         [-1, 64, 128, 128]               0\n",
            "           Conv2d-54         [-1, 64, 128, 128]          73,792\n",
            "      BatchNorm2d-55         [-1, 64, 128, 128]             128\n",
            "             ReLU-56         [-1, 64, 128, 128]               0\n",
            "           Conv2d-57         [-1, 32, 128, 128]          18,464\n",
            "      BatchNorm2d-58         [-1, 32, 128, 128]              64\n",
            "             ReLU-59         [-1, 32, 128, 128]               0\n",
            "       DoubleConv-60         [-1, 32, 128, 128]               0\n",
            "               Up-61         [-1, 32, 128, 128]               0\n",
            "         Upsample-62         [-1, 32, 256, 256]               0\n",
            "           Conv2d-63         [-1, 32, 256, 256]          18,464\n",
            "      BatchNorm2d-64         [-1, 32, 256, 256]              64\n",
            "             ReLU-65         [-1, 32, 256, 256]               0\n",
            "           Conv2d-66         [-1, 16, 256, 256]           4,624\n",
            "      BatchNorm2d-67         [-1, 16, 256, 256]              32\n",
            "             ReLU-68         [-1, 16, 256, 256]               0\n",
            "       DoubleConv-69         [-1, 16, 256, 256]               0\n",
            "               Up-70         [-1, 16, 256, 256]               0\n",
            "         Upsample-71         [-1, 16, 512, 512]               0\n",
            "           Conv2d-72         [-1, 16, 512, 512]           4,624\n",
            "      BatchNorm2d-73         [-1, 16, 512, 512]              32\n",
            "             ReLU-74         [-1, 16, 512, 512]               0\n",
            "           Conv2d-75         [-1, 16, 512, 512]           2,320\n",
            "      BatchNorm2d-76         [-1, 16, 512, 512]              32\n",
            "             ReLU-77         [-1, 16, 512, 512]               0\n",
            "       DoubleConv-78         [-1, 16, 512, 512]               0\n",
            "               Up-79         [-1, 16, 512, 512]               0\n",
            "           Conv2d-80         [-1, 16, 512, 512]           2,320\n",
            "      BatchNorm2d-81         [-1, 16, 512, 512]              32\n",
            "             ReLU-82         [-1, 16, 512, 512]               0\n",
            "           Conv2d-83         [-1, 16, 512, 512]           2,320\n",
            "      BatchNorm2d-84         [-1, 16, 512, 512]              32\n",
            "             ReLU-85         [-1, 16, 512, 512]               0\n",
            "       DoubleConv-86         [-1, 16, 512, 512]               0\n",
            "           Conv2d-87         [-1, 16, 512, 512]           2,320\n",
            "      BatchNorm2d-88         [-1, 16, 512, 512]              32\n",
            "             ReLU-89         [-1, 16, 512, 512]               0\n",
            "           Conv2d-90         [-1, 16, 512, 512]           2,320\n",
            "      BatchNorm2d-91         [-1, 16, 512, 512]              32\n",
            "             ReLU-92         [-1, 16, 512, 512]               0\n",
            "       DoubleConv-93         [-1, 16, 512, 512]               0\n",
            "           Conv2d-94         [-1, 16, 512, 512]           2,320\n",
            "      BatchNorm2d-95         [-1, 16, 512, 512]              32\n",
            "             ReLU-96         [-1, 16, 512, 512]               0\n",
            "           Conv2d-97         [-1, 16, 512, 512]           2,320\n",
            "      BatchNorm2d-98         [-1, 16, 512, 512]              32\n",
            "             ReLU-99         [-1, 16, 512, 512]               0\n",
            "      DoubleConv-100         [-1, 16, 512, 512]               0\n",
            "          Conv2d-101          [-1, 1, 512, 512]              17\n",
            "high_capicity_conv-102          [-1, 1, 512, 512]               0\n",
            "          Conv2d-103         [-1, 16, 512, 512]           2,320\n",
            "     BatchNorm2d-104         [-1, 16, 512, 512]              32\n",
            "            ReLU-105         [-1, 16, 512, 512]               0\n",
            "          Conv2d-106         [-1, 16, 512, 512]           2,320\n",
            "     BatchNorm2d-107         [-1, 16, 512, 512]              32\n",
            "            ReLU-108         [-1, 16, 512, 512]               0\n",
            "      DoubleConv-109         [-1, 16, 512, 512]               0\n",
            "          Conv2d-110         [-1, 16, 512, 512]           2,320\n",
            "     BatchNorm2d-111         [-1, 16, 512, 512]              32\n",
            "            ReLU-112         [-1, 16, 512, 512]               0\n",
            "          Conv2d-113         [-1, 16, 512, 512]           2,320\n",
            "     BatchNorm2d-114         [-1, 16, 512, 512]              32\n",
            "            ReLU-115         [-1, 16, 512, 512]               0\n",
            "      DoubleConv-116         [-1, 16, 512, 512]               0\n",
            "          Conv2d-117         [-1, 16, 512, 512]           2,320\n",
            "     BatchNorm2d-118         [-1, 16, 512, 512]              32\n",
            "            ReLU-119         [-1, 16, 512, 512]               0\n",
            "          Conv2d-120         [-1, 16, 512, 512]           2,320\n",
            "     BatchNorm2d-121         [-1, 16, 512, 512]              32\n",
            "            ReLU-122         [-1, 16, 512, 512]               0\n",
            "      DoubleConv-123         [-1, 16, 512, 512]               0\n",
            "          Conv2d-124          [-1, 1, 512, 512]              17\n",
            "high_capicity_conv-125          [-1, 1, 512, 512]               0\n",
            "================================================================\n",
            "Total params: 1,110,274\n",
            "Trainable params: 1,110,274\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.00\n",
            "Forward/backward pass size (MB): 2293.00\n",
            "Params size (MB): 4.24\n",
            "Estimated Total Size (MB): 2300.24\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qX5SyM9oJwr"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abYx1EHkHmIH"
      },
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch, device, weights):\n",
        "    model.train()\n",
        "    stream = tqdm(train_loader)\n",
        "    for i, (images, target) in enumerate(stream, start=1):\n",
        "        images = images.to(device)\n",
        "        eyes,lips = model(images)\n",
        "        target = target.to(device, dtype=torch.float32)\n",
        "        target_channel_first = target.permute(1,0,2,3) \n",
        "\n",
        "        loss_eyes  = criterion(eyes.squeeze(), target_channel_first[0])\n",
        "        loss_lips = criterion(lips.squeeze(), target_channel_first[1])\n",
        "\n",
        "        loss = loss_eyes * weights[0] + loss_lips * weights[1] \n",
        "        loss = loss / (sum(weights))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        stream.set_description(\n",
        "            \"Epoch: {epoch}. Train.  Loss:{loss}    \".format(epoch=epoch,loss={loss.item()})\n",
        "        )\n",
        "\n",
        "def validate(val_loader, model, criterion, epoch, device):\n",
        "    model.eval()\n",
        "    stream = tqdm(val_loader)\n",
        "    with torch.no_grad():\n",
        "        for i, (images, target) in enumerate(stream, start=1):\n",
        "            images = images.to(device)\n",
        "            eyes,lips = model(images)\n",
        "            target = target.to(device, dtype=torch.float32)\n",
        "            target_channel_first = target.permute(1,0,2,3) \n",
        "\n",
        "            loss_eyes  = criterion(eyes.squeeze(), target_channel_first[0])\n",
        "            loss_lips = criterion(lips.squeeze(), target_channel_first[1])\n",
        "\n",
        "            loss = loss_eyes * 1 + loss_lips * 1\n",
        "            loss = loss / 2\n",
        "            # metric_monitor.update(\"Loss\", loss.item())\n",
        "            stream.set_description(\n",
        "                \"Epoch: {epoch}. Validation. Val Loss:{loss} \".format(epoch=epoch,loss={loss.item()})\n",
        "            )"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ptc9a-ahRg1"
      },
      "source": [
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(SoftDiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        smooth = 1\n",
        "        num = targets.size(0)\n",
        "        \"\"\"\n",
        "       I am assuming the model does not have sigmoid layer in the end. if that is the case, change torch.sigmoid(logits) to simply logits\n",
        "        \"\"\"\n",
        "        probs = torch.sigmoid(logits)\n",
        "        # print(\"probs max\",torch.max(probs))\n",
        "        # print(\"probs min\",torch.min(probs))\n",
        "        m1 = probs.view(num, -1)\n",
        "        m2 = targets.view(num, -1)\n",
        "        intersection = (m1 * m2)\n",
        "\n",
        "        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
        "        score = 1 - score.sum() / num\n",
        "        return score"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pypVZnXkZH9p"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itcva49ddtse",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "f0a21896-5348-48a3-d4b9-8a665edef6f5"
      },
      "source": [
        "criterion = SoftDiceLoss().to(device) \n",
        "optimizer = torch.optim.SGD(unet.parameters(), lr=lr)\n",
        "weights = [3.,1.]\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "  train(train_dataloader, unet, criterion, optimizer, epoch, device, weights)\n",
        "  torch.save(unet,\"/content/drive/MyDrive/CelebAMask/unet_epoch\"+str(epoch)+\".pt\")\n",
        "  if(epoch==5):\n",
        "    validate(val_dataloader, unet, criterion, epoch, device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1. Train.  Loss:{0.9591552019119263}    : 100%|██████████| 1631/1631 [58:25<00:00,  2.15s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-382fba2457d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CelebAMask/unet_epoch\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CelebAMask/unet_epoch1.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6BNRW0VMbjk"
      },
      "source": [
        "torch.save(unet,\"/content/drive/MyDrive/Colab Notebooks/Unet/unet_epoch\"+str(epoch)+\".pt\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "DxVnfo9MnPaR",
        "outputId": "4d1ea8f7-834c-4e78-f152-d595013d7b66"
      },
      "source": [
        "criterion = SoftDiceLoss().to(device) \n",
        "optimizer = torch.optim.SGD(unet.parameters(), lr=lr)\n",
        "weights = [3.,1.]\n",
        "\n",
        "for epoch in range(2, epochs + 1):\n",
        "  train(train_dataloader, unet, criterion, optimizer, epoch, device, weights)\n",
        "  torch.save(unet,\"/content/drive/MyDrive/Colab\\ Notebooks/Unet/unet_epoch\"+str(epoch)+\".pt\")\n",
        "  if(epoch==5):\n",
        "    validate(val_dataloader, unet, criterion, epoch, device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2. Train.  Loss:{0.8400422930717468}    : 100%|██████████| 1631/1631 [57:40<00:00,  2.12s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-aaf6441e0e56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab\\ Notebooks/Unet/unet_epoch\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab\\\\ Notebooks/Unet/unet_epoch2.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "sCsFUpRbnW8C",
        "outputId": "2f664ca5-3507-4b2e-cc9c-7ad882e55198"
      },
      "source": [
        "criterion = SoftDiceLoss().to(device) \n",
        "optimizer = torch.optim.SGD(unet.parameters(), lr=lr)\n",
        "weights = [3.,1.]\n",
        "\n",
        "for epoch in range(3, epochs + 1):\n",
        "  train(train_dataloader, unet, criterion, optimizer, epoch, device, weights)\n",
        "  torch.save(unet,\"/content/drive/MyDrive/Colab Notebooks/Unet/unet_epoch\"+str(epoch)+\".pt\")\n",
        "  if(epoch==5):\n",
        "    validate(val_dataloader, unet, criterion, epoch, device)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3. Train.  Loss:{0.2073861062526703}    : 100%|██████████| 1631/1631 [57:44<00:00,  2.12s/it]\n",
            "Epoch: 4. Train.  Loss:{0.11479796469211578}    : 100%|██████████| 1631/1631 [57:37<00:00,  2.12s/it]\n",
            "Epoch: 5. Train.  Loss:{0.08407671749591827}    : 100%|██████████| 1631/1631 [57:19<00:00,  2.11s/it]\n",
            "  0%|          | 0/182 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ce2c3f6ca343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/Unet/unet_epoch\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-ec546c8cf30d>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(val_loader, model, criterion, epoch, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;31m# metric_monitor.update(\"Loss\", loss.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             stream.set_description(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d5da5627f9ef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, logits, targets)\u001b[0m\n\u001b[1;32m      9\u001b[0m        \u001b[0mI\u001b[0m \u001b[0mam\u001b[0m \u001b[0massuming\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhave\u001b[0m \u001b[0msigmoid\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mto\u001b[0m \u001b[0msimply\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \"\"\"\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# print(\"probs max\",torch.max(probs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# print(\"probs min\",torch.min(probs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sigmoid(): argument 'input' (position 1) must be Tensor, not tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOr7ZNH31Gg7",
        "outputId": "b3cf09cb-4e83-4368-d888-8ae0826e40b3"
      },
      "source": [
        "validate(val_dataloader, unet, criterion, epoch, device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5. Validation. Val Loss:{0.11279505491256714} : 100%|██████████| 182/182 [02:34<00:00,  1.18it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km31gopKnI4x"
      },
      "source": [
        "## Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRbArqeAnKfq"
      },
      "source": [
        "class Validation_SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(Validation_SoftDiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        smooth = 1\n",
        "        num = targets.size(0)\n",
        "        \"\"\"\n",
        "       I am assuming the model does not have sigmoid layer in the end. if that is the case, change torch.sigmoid(logits) to simply logits\n",
        "        \"\"\"\n",
        "        probs = torch.sigmoid(logits)\n",
        "        probs[probs>0.5] = 1.0\n",
        "        probs[probs<=0.5] = 0.0\n",
        "        # print(\"probs shapre\",probs.shape)\n",
        "        # print(\"target shape\",targets.shape)\n",
        "        m1 = probs.view(num, -1)\n",
        "        m2 = targets.view(num, -1)\n",
        "        intersection = (m1 * m2)\n",
        "\n",
        "        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
        "        dice_score = score.sum() / num\n",
        "        return dice_score\n",
        "\n",
        "def validate(val_loader, model, criterion, epoch, device):\n",
        "    model.eval()\n",
        "    stream = tqdm(val_loader)\n",
        "    total_dice_score = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (images, target) in enumerate(stream, start=1):\n",
        "            images = images.to(device)\n",
        "            target = target.to(device, dtype=torch.float32)\n",
        "            eyes,lips = model(images)\n",
        "            target_channel_first = target.permute(1,0,2,3)\n",
        "\n",
        "            dice_score_eyes  = criterion(eyes.squeeze(), target_channel_first[0])\n",
        "            dice_score_lips = criterion(lips.squeeze(), target_channel_first[1])\n",
        "            dice_score = dice_score_eyes * 1  + dice_score_lips * 1 \n",
        "            dice_score = dice_score / 2\n",
        "\n",
        "            # loss = criterion(output, target)\n",
        "            total_dice_score += dice_score\n",
        "            # metric_monitor.update(\"Loss\", loss.item())\n",
        "            stream.set_description(\n",
        "                \"Epoch: {epoch}. Validation. Val dice_score:{dice_score} \".format(epoch=epoch,dice_score={dice_score.item()})\n",
        "            )\n",
        "        avg_dice_score = total_dice_score/(i+1)\n",
        "    return avg_dice_score"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4d_j0ccnpe3",
        "outputId": "0878e9c5-b51f-451e-9ff8-04ec4d9bbb3d"
      },
      "source": [
        "epoch = 1\n",
        "criterion  = Validation_SoftDiceLoss().to(device)\n",
        "dice_score = validate(val_dataloader, unet, criterion, epoch, device)\n",
        "print(\"dice_score on test dataset:\", dice_score)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1. Validation. Val dice_score:{0.8940052390098572} : 100%|██████████| 182/182 [02:26<00:00,  1.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dice_score on test dataset: tensor(0.8884, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjJq67sZot3r",
        "outputId": "1f6d2036-40c6-40fb-8862-f75ed2b268c1"
      },
      "source": [
        "print(\"dice_score on test dataset:\", dice_score.item())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dice_score on test dataset: 0.8884453177452087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N2mB6OrqoKs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}